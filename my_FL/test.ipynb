{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLIENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "class Client():\n",
    "    def __init__(self, client_id:str, model:nn.Module, data_info:dict=None, device:str=cfg.DEVICE):\n",
    "        self.id = client_id\n",
    "        #self.cfg = cfg\n",
    "        \n",
    "        self.__model = None\n",
    "        self.device = device\n",
    "        \n",
    "        self.train_info, self.test_info = data_info['train'], data_info['test'] # 함수화하기\n",
    "        self.trainset, self.testset = FEMNIST(self.train_info), FEMNIST(self.test_info)\n",
    "        \n",
    "    @property\n",
    "    def model(self):             \n",
    "        return self.__model\n",
    "\n",
    "    @model.setter\n",
    "    def model(self, model):\n",
    "        self.__model = model\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.trainset)\n",
    "    \n",
    "    def setup(self):\n",
    "        self.train_loader = DataLoader(self.trainset, batch_size=16, shuffle=True)\n",
    "        self.test_loader = DataLoader(self.testset, batch_size=16, shuffle=False)\n",
    "        self.optimizer = SGD(self.model.parameters(), lr=0.01)     # TODO: utils.get_optimizer(cfg['optim']:str)\n",
    "        self.criterion = nn.CrossEntropyLoss()                       # TODO: utils.get_loss(cfg['loss']:str)\n",
    "        self.epochs = 10\n",
    "    \n",
    "    def local_train(self)->None:\n",
    "        proc = os.getpid()\n",
    "        self.model.train()\n",
    "        self.model.to(self.device)\n",
    "        # TRAINING\n",
    "        for epoch in range(self.epochs):\n",
    "            for idx, batch in enumerate(self.train_loader):\n",
    "                self.optimizer.zero_grad()\n",
    "                X, Y = batch\n",
    "                X, Y = X.to(self.device), Y.to(self.device)\n",
    "                pred = self.model(X)\n",
    "                loss = self.criterion(pred, Y)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                if \"cuda\" in self.device : torch.cuda.empty_cache()\n",
    "        # TESTING\n",
    "        self.model.eval()\n",
    "        self.model.to(self.device)\n",
    "        with torch.no_grad():\n",
    "            loss_trace, result_pred, result_anno = [], [], []\n",
    "            for idx, batch in enumerate(self.train_loader):\n",
    "                X, Y = batch\n",
    "                X, Y = X.to(self.device), Y.to(self.device)\n",
    "                pred = self.model(X)\n",
    "                loss = self.criterion(pred, Y)\n",
    "                loss_trace.append(loss.to('cpu').detach().numpy())\n",
    "                pred_np  = pred.to('cpu').detach().numpy()\n",
    "                pred_np  = np.argmax(pred_np, axis=1).squeeze()\n",
    "                Y_np     = Y.to('cpu').detach().numpy().reshape(-1, 1).squeeze()\n",
    "                result_pred = np.hstack((result_pred, pred_np))\n",
    "                result_anno = np.hstack((result_anno, Y_np))\n",
    "                if \"cuda\" in self.device : torch.cuda.empty_cache()\n",
    "            train_acc = metrics.accuracy_score(y_true=result_anno, y_pred=result_pred)\n",
    "            train_loss = np.average(loss_trace)\n",
    "            self.model.to('cpu')\n",
    "        \n",
    "        print(f'=== Process ID: {proc} | Client {self.id} Finished Training {len(self)} samples ===')\n",
    "        print(f'client:{self.id} | Train Acc:{train_acc*100:.2f} | Train Loss:{train_loss:.4f}')\n",
    "    \n",
    "    def local_test(self):\n",
    "        self.model.eval()\n",
    "        self.model.to(self.device)\n",
    "        with torch.no_grad():\n",
    "            loss_trace, result_pred, result_anno = [], [], []\n",
    "            for idx, batch in enumerate(self.test_loader):\n",
    "                X, Y = batch\n",
    "                X, Y = X.to(self.device), Y.to(self.device)\n",
    "                pred = self.model(X)\n",
    "                loss = self.criterion(pred, Y)\n",
    "                loss_trace.append(loss.to('cpu').detach().numpy())\n",
    "                pred_np  = pred.to('cpu').detach().numpy()\n",
    "                pred_np  = np.argmax(pred_np, axis=1).squeeze()\n",
    "                Y_np     = Y.to('cpu').detach().numpy().reshape(-1, 1).squeeze()\n",
    "                result_pred = np.hstack((result_pred, pred_np))\n",
    "                result_anno = np.hstack((result_anno, Y_np))\n",
    "                \n",
    "                if \"cuda\" in self.device : torch.cuda.empty_cache()\n",
    "                \n",
    "            test_acc = metrics.accuracy_score(y_true=result_anno, y_pred=result_pred)\n",
    "            test_loss = np.average(loss_trace)\n",
    "            print(f'client:{self.id} | Test Acc:{test_acc*100:.2f} | Test Loss:{test_loss:.4f}')\n",
    "            self.model.to('cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SERVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server():\n",
    "    def __init__(self, DM_dict:dict, algorithm:str=None):\n",
    "        self.train_DM = DM_dict['train']\n",
    "        self.test_DM = DM_dict['test']\n",
    "        \n",
    "        self.clients = None\n",
    "        self.device = cfg.DEVICE\n",
    "        \n",
    "        self.global_model = Net()\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()              # TODO: utils.get_loss(cfg['loss']:str)\n",
    "        \n",
    "        self.Algorithm = FedAvg.FedAvg                      # FedAVG 같은 aggrrgation method 들어감 TODO: utils.get_algortihm() 작성\n",
    "        self.received_models = None                         # Client.upload_model() 결과가 여기 들어감\n",
    "        \n",
    "        self.mp_flag = True\n",
    "\n",
    "    def setup(self):\n",
    "        self.clients = self.create_clients()\n",
    "        self.data = FEMNIST(self.test_DM.get_global_testset())\n",
    "        self.dataloader = DataLoader(self.data, batch_size=256, shuffle=False)\n",
    "        \n",
    "        self.transmit_model()\n",
    "        self.setup_clients()\n",
    "        \n",
    "        \n",
    "    def create_clients(self, n_users:int=100):\n",
    "        self.user_ids = self.test_DM.users\n",
    "        self.user_ids = np.random.choice(self.user_ids, n_users, replace=False)\n",
    "        clients = {}\n",
    "        for user in self.user_ids:\n",
    "            data_info = {'train':self.train_DM.get_user_info(user),\\\n",
    "                         'test':self.test_DM.get_user_info(user)}\n",
    "            clients[user] = Client(client_id=user, model=self.global_model, data_info=data_info)\n",
    "        return clients\n",
    "    \n",
    "    def setup_clients(self)->None:\n",
    "        for k, client in tqdm(enumerate(self.clients), leave=False):\n",
    "            self.clients[client].setup()\n",
    "    \n",
    "    def transmit_model(self, sampled_clients:list=None)->None:\n",
    "        if sampled_clients == None:\n",
    "            for client in tqdm(self.clients, leave=False):\n",
    "                self.clients[client].model = copy.deepcopy(self.global_model)\n",
    "        else:\n",
    "            for client in tqdm(sampled_clients, leave=False):\n",
    "                self.clients[client].model = copy.deepcopy(self.global_model)\n",
    "\n",
    "        \n",
    "    def sample_clients(self, n_participant:int=50)->np.array:\n",
    "        assert n_participant <= len(self.user_ids), \"Check 'n_participant <= len(self.clients)'\"\n",
    "        return np.random.choice(self.user_ids, n_participant, replace=False) # 입력된 수의 유저를 추출해서 반환\n",
    "\n",
    "    def train_selected_clients(self, sampled_clients:list)->None:\n",
    "        total_sample = 0\n",
    "        for client in tqdm(sampled_clients, leave=False):\n",
    "            self.clients[client].local_train()\n",
    "            total_sample += len(self.clients[client])\n",
    "\n",
    "    def mp_train_selected_clients(self, client:str)->None:\n",
    "        self.clients[client].local_train()\n",
    "        n_sample = len(self.clients[client])\n",
    "        return n_sample\n",
    "    \n",
    "    def test_selected_models(self, sampled_clients):\n",
    "        for client in sampled_clients:\n",
    "            self.clients[client].local_test()\n",
    "\n",
    "    def mp_test_selected_models(self, client):\n",
    "        self.clients[client].local_test()\n",
    "    \n",
    "    def average_model(self, sampled_clients, coefficients):\n",
    "        averaged_weights = OrderedDict()\n",
    "        for it, client in tqdm(enumerate(sampled_clients), leave=False):\n",
    "            local_weights = self.clients[client].model.state_dict()\n",
    "            for key in self.global_model.state_dict().keys():\n",
    "                if it == 0:\n",
    "                    averaged_weights[key] = coefficients[it] * local_weights[key]\n",
    "                else:\n",
    "                    averaged_weights[key] += coefficients[it] * local_weights[key]\n",
    "        self.global_model.load_state_dict(averaged_weights)\n",
    "    \n",
    "    def update_model(self, train_result:dict, layers:list=None):\n",
    "        self.received_models, num_samples = [], []\n",
    "        for result in train_result:\n",
    "            self.received_models.append(result['model'])\n",
    "            num_samples.append(result['num_sample'])\n",
    "        state = self.Algorithm(self.received_models, num_samples, layers)\n",
    "        self.global_model.load_state_dict(state)\n",
    "\n",
    "    def train_federated_model(self):\n",
    "        sampled_clients = self.sample_clients()\n",
    "        \n",
    "        if self.mp_flag:\n",
    "            with pool.ThreadPool(processes=cpu_count() - 1) as workhorse:\n",
    "                selected_total_size = workhorse.map(self.mp_train_selected_clients, sampled_clients)\n",
    "            selected_total_size = sum(selected_total_size)\n",
    "        else:\n",
    "            selected_total_size = self.train_selected_clients(sampled_clients)\n",
    "\n",
    "        if self.mp_flag:\n",
    "            with pool.ThreadPool(processes=cpu_count() - 1) as workhorse:\n",
    "                workhorse.map(self.mp_test_selected_models, sampled_clients)\n",
    "        else:\n",
    "            self.test_selected_models(sampled_clients)\n",
    "        \n",
    "        mixing_coefficients = [len(self.clients[client]) / selected_total_size for client in sampled_clients]\n",
    "        \n",
    "        self.average_model(sampled_clients, mixing_coefficients)\n",
    "        \n",
    "    def global_test(self):\n",
    "        self.global_model.eval()\n",
    "        self.global_model.to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            loss_trace, result_pred, result_anno = [], [], []\n",
    "            for idx, batch in enumerate(self.dataloader):\n",
    "                X, Y = batch\n",
    "                X, Y = X.to(self.device), Y.to(self.device)\n",
    "                pred = self.global_model(X)\n",
    "                loss = self.criterion(pred, Y)\n",
    "                loss_trace.append(loss.to('cpu').detach().numpy())\n",
    "                pred_np  = pred.to('cpu').detach().numpy()\n",
    "                pred_np  = np.argmax(pred_np, axis=1).squeeze()\n",
    "                Y_np     = Y.to('cpu').detach().numpy().reshape(-1, 1).squeeze()\n",
    "                result_pred = np.hstack((result_pred, pred_np))\n",
    "                result_anno = np.hstack((result_anno, Y_np))\n",
    "            self.acc = metrics.accuracy_score(y_true=result_anno, y_pred=result_pred)\n",
    "            self.test_loss = np.average(loss_trace)\n",
    "            print(f'Global Test Result | Acc:{self.acc*100:.2f}, Loss:{self.test_loss:.4f}')\n",
    "            self.global_model.to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA READY\n"
     ]
    }
   ],
   "source": [
    "PATH = cfg.DATAPATH['femnist']\n",
    "    \n",
    "file_dict = get_files(PATH)\n",
    "    \n",
    "TRAIN_DM = DataManager(file_dict['train'], is_train=True)\n",
    "TEST_DM = DataManager(file_dict['test'], is_train=False)\n",
    "DM_dict = {'train':TRAIN_DM,\n",
    "            'test':TEST_DM}\n",
    "print(\"DATA READY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = Server(DM_dict)\n",
    "#server.create_clients()\n",
    "server.setup()\n",
    "for i in range(100):\n",
    "    server.train_federated_model()\n",
    "    server.global_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = server.train_DM.files[0]\n",
    "with open(file) as f:\n",
    "    data = json.load(f)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141, 784)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data['user_data'][data['users'][0]]['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataManager():\n",
    "    def __init__(self, files:list, is_train:bool=True):\n",
    "        self.files = files\n",
    "        self.is_train = is_train\n",
    "        self.users, self.data = [], {}\n",
    "        if not self.is_train:\n",
    "            self.global_test_data = {'x':[], 'y':[]}\n",
    "        \n",
    "        for idx, file in enumerate(self.files):\n",
    "            idx = str(idx)\n",
    "            self.data[idx] = {'x':[], 'y':[]}\n",
    "            with open(file) as f:\n",
    "                data = json.load(f)\n",
    "                self.users.append(idx)\n",
    "\n",
    "                for user in data['users']:              # 각 유저의 data 저장\n",
    "                    self.data[idx]['x'] = self.data[idx]['x'] + data['user_data'][user]['x']\n",
    "                    self.data[idx]['y'] = self.data[idx]['y'] + data['user_data'][user]['y']\n",
    "                    \n",
    "                if not self.is_train:                   # test dataset인 경우 global evaluation 위해서 모든 데이터셋 저장\n",
    "                    for user in data['users']:\n",
    "                        self.global_test_data['x'] = self.global_test_data['x'] + data['user_data'][user]['x']\n",
    "                        self.global_test_data['y'] = self.global_test_data['y'] + data['user_data'][user]['y']\n",
    "\n",
    "class FEMNIST(Dataset):\n",
    "    def __init__(self, data:dict):\n",
    "        self.data = data\n",
    "        self.data['x'] = np.array(data['x'])\n",
    "        self.data['y'] = np.array(data['y'])\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        #self.X = torch.tensor(self.data['x'][idx,:].reshape(1, 28, 28)).float()\n",
    "        self.X = torch.tensor(self.data['x'][idx,:]).float()\n",
    "        self.Y = torch.tensor(self.data['y'][idx]).long()\n",
    "        return self.X, self.Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../leaf/data/femnist/data/train'\n",
    "files = [os.path.join(PATH, file) for file in os.listdir(PATH) if file.endswith('.json')]\n",
    "files.sort()\n",
    "\n",
    "DM = DataManager(files, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 784)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(DM.data['1']['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2754, 784)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(DM.data['0']['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FEMNIST(DM.data['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 0.9961, 0.9961, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 0.9961, 0.9961, 0.9412, 0.8824, 1.0000, 0.9961, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 0.9882, 1.0000, 0.4863, 0.5255, 1.0000, 0.9843, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 0.9961, 0.9961, 0.9647, 0.1333, 0.8627, 1.0000, 0.9922,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 0.9882, 1.0000, 0.4824, 0.2588, 1.0000, 0.9882,\n",
       "         0.9961, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 0.9882, 0.9961, 0.8000, 0.1216, 0.7216, 0.9961,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 0.9922, 1.0000, 0.3098, 0.4902, 1.0000,\n",
       "         0.9882, 0.9529, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 0.9922, 1.0000, 0.9059, 0.1059, 0.5412,\n",
       "         0.4392, 0.1294, 0.0039, 0.4039, 0.9686, 0.9922, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9882, 0.9529, 0.3569, 0.0000,\n",
       "         0.0000, 0.0275, 0.2667, 0.2863, 0.0000, 0.7804, 1.0000, 0.9922, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9922, 1.0000, 0.7882, 0.0000,\n",
       "         0.0118, 0.3765, 0.9020, 1.0000, 0.6196, 0.1176, 0.9647, 0.9961, 0.9961,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9961, 0.9922, 0.9373,\n",
       "         0.2235, 0.0000, 0.1882, 0.0824, 0.0667, 0.0314, 0.5451, 1.0000, 0.9882,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9922,\n",
       "         1.0000, 0.8745, 0.3216, 0.1765, 0.2980, 0.4706, 0.8627, 1.0000, 0.9961,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 0.9961, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9961,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 0.9922, 0.9922, 0.9922, 0.9922, 0.9882, 0.9922,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000]),\n",
       " tensor(6))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b3ded1ccb95c1d9bd405e7b823d9e85424cde40fbb5985eb47e999ef50e15b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
